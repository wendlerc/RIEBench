{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\"HF_HOME\"] = \"/tmp/wendler/hf_cache\"\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(\"./sdxl-unbox\")\n",
    "\n",
    "from SDLens import HookedStableDiffusionXLPipeline\n",
    "from SAE import SparseAutoencoder\n",
    "\n",
    "# Grounded SAM2 and Grounding DINO imports\n",
    "sys.path.append(\"./Grounded-SAM-2\")\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "from grounding_dino.groundingdino.util.inference import load_model\n",
    "from interventions import code_to_block,run_feature_transport\n",
    "import os\n",
    "import json \n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "k = 10\n",
    "exp = 4\n",
    "n_steps = 4\n",
    "m1 = 2.\n",
    "k_transfer = 80\n",
    "use_down = True\n",
    "use_up = True\n",
    "use_up0 = True\n",
    "use_mid = True\n",
    "n_examples_per_edit = 50\n",
    "prefix = './results/'\n",
    "path_to_checkpoints = \"./sdxl-unbox/checkpoints\" # \"./sdxl-turbo-saes\"\n",
    "dtype = \"float32\"\n",
    "mode = \"sae\" \n",
    "stat = \"mean\"\n",
    "aggregate_timesteps = \"first\"\n",
    "keep_spatial_info = True\n",
    "subtract_target_add_source = True\n",
    "only_add = False\n",
    "task_ids = \"1,2,3,4,5,6,7,8,9\"\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert mode in [\"sae\", \"neurons\", \"steering\", \"sae_adaptive\"]\n",
    "task_ids = task_ids.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dtype == \"float16\":\n",
    "    dtype = torch.float16\n",
    "else:\n",
    "    dtype = torch.float32\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "pipe = HookedStableDiffusionXLPipeline.from_pretrained(\n",
    "    'stabilityai/sdxl-turbo',\n",
    "    torch_dtype=dtype,\n",
    "    device_map=\"balanced\",\n",
    "    variant=(\"fp16\" if dtype==torch.float16 else None)\n",
    ")\n",
    "if dtype == torch.float32:\n",
    "    pipe.text_encoder_2.to(dtype=dtype)\n",
    "pipe.set_progress_bar_config(disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAM2_CHECKPOINT = \"./Grounded-SAM-2/checkpoints/sam2.1_hiera_large.pt\"\n",
    "SAM2_MODEL_CONFIG = \"configs/sam2.1/sam2.1_hiera_l.yaml\"\n",
    "GROUNDING_DINO_CONFIG = \"./Grounded-SAM-2/grounding_dino/groundingdino/config/GroundingDINO_SwinT_OGC.py\"\n",
    "GROUNDING_DINO_CHECKPOINT = \"./Grounded-SAM-2/gdino_checkpoints/groundingdino_swint_ogc.pth\"\n",
    "BOX_THRESHOLD = 0.35\n",
    "TEXT_THRESHOLD = 0.25\n",
    "sam2_model = build_sam2(SAM2_MODEL_CONFIG, SAM2_CHECKPOINT, device=device)\n",
    "sam2_predictor = SAM2ImagePredictor(sam2_model)\n",
    "grounding_model = load_model(\n",
    "    model_config_path=GROUNDING_DINO_CONFIG,\n",
    "    model_checkpoint_path=GROUNDING_DINO_CHECKPOINT,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "blocks = list(code_to_block.values())\n",
    "saes = {}\n",
    "for shortcut in code_to_block.keys():\n",
    "    block = code_to_block[shortcut]\n",
    "    sae = SparseAutoencoder.load_from_disk(\n",
    "        os.path.join(path_to_checkpoints, f\"{block}_k{k}_hidden{exp*1280:d}_auxk256_bs4096_lr0.0001\", \"final\")\n",
    "    ).to(device, dtype=dtype)\n",
    "    saes[shortcut] = sae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug:\n",
    "    out = run_feature_transport(\"a cat in front of a grey background\", \"a cat with a hat in front of a grey background\", \"#everything\", \"hat\", \n",
    "                    pipe, grounding_model, sam2_predictor, saes,\n",
    "                    blocks_to_intervene=[\"down.2.1\", \"mid.0\",\"up.0.0\",\"up.0.1\"], combine_blocks=True, \n",
    "                    subtract_target_add_source=True,\n",
    "                    use_target_mask_in_both=True,\n",
    "                    maintain_spatial_info=True,\n",
    "                    n_steps=4, m1=1., k_transfer=10, stat=\"mean\", mode=\"steering\", \n",
    "                    aggregate_timesteps=\"first\",\n",
    "                    result_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug:\n",
    "    out = run_feature_transport(\"a cat in front of a grey background\", \"a cat with a headphones in front of a grey background\", \"#everything\", \"headphones\", \n",
    "                    pipe, grounding_model, sam2_predictor, saes,\n",
    "                    blocks_to_intervene=[\"down.2.1\", \"mid.0\",\"up.0.0\",\"up.0.1\"], combine_blocks=True, \n",
    "                    subtract_target_add_source=True,\n",
    "                    use_target_mask_in_both=True,\n",
    "                    maintain_spatial_info=True,\n",
    "                    n_steps=4, m1=1., k_transfer=10, stat=\"mean\", mode=\"steering\", \n",
    "                    aggregate_timesteps=\"first\",\n",
    "                    result_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug:\n",
    "    out = run_feature_transport(\"a photo of a giraffe\", \"a photo of a colorful model\", \"giraffe\", \"face\", \n",
    "                    pipe, grounding_model, sam2_predictor, saes,\n",
    "                    blocks_to_intervene=[\"down.2.1\", \"mid.0\",\"up.0.0\",\"up.0.1\"], combine_blocks=True, \n",
    "                    subtract_target_add_source=False,\n",
    "                    maintain_spatial_info=False,\n",
    "                    n_steps=4, m1=1., k_transfer=200, \n",
    "                    stat=\"mean\", \n",
    "                    mode=\"sae\", \n",
    "                    aggregate_timesteps=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug:\n",
    "    out = run_feature_transport(\"a photo of a black panther\", \"a photo of a colorful model\", \"panther\", \"face\", \n",
    "                    pipe, grounding_model, sam2_predictor, saes,\n",
    "                    blocks_to_intervene=[\"down.2.1\", \"mid.0\",\"up.0.0\",\"up.0.1\"], combine_blocks=True, \n",
    "                    subtract_target_add_source=True,\n",
    "                    maintain_spatial_info=True,\n",
    "                    n_steps=4, m1=1., k_transfer=200, \n",
    "                    stat=\"mean\", \n",
    "                    mode=\"sae\", \n",
    "                    aggregate_timesteps=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug:\n",
    "    out = run_feature_transport(\"a photo of a giraffe\", \"a photo of a colorful model\", \"giraffe\", \"face\", \n",
    "                    pipe, grounding_model, sam2_predictor, saes,\n",
    "                    blocks_to_intervene=[\"down.2.1\", \"mid.0\",\"up.0.0\",\"up.0.1\"], combine_blocks=True, \n",
    "                    subtract_target_add_source=False,\n",
    "                    maintain_spatial_info=False,\n",
    "                    n_steps=4, m1=1., k_transfer=100000, \n",
    "                    stat=\"mean\", \n",
    "                    mode=\"neurons\", \n",
    "                    aggregate_timesteps=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./dataset/riebench.json\", \"r\") as f:\n",
    "    rb = json.load(f)\n",
    "\n",
    "rb[0] # source and target are mixed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "blocks_to_intervene = []\n",
    "if use_down:\n",
    "     blocks_to_intervene.append(\"down.2.1\")\n",
    "if use_up:\n",
    "     blocks_to_intervene.append(\"up.0.1\")\n",
    "if use_up0:\n",
    "     blocks_to_intervene.append(\"up.0.0\")\n",
    "if use_mid:\n",
    "     blocks_to_intervene.append(\"mid.0\")\n",
    "\n",
    "expid2name= {\"0\":\"random\",\n",
    "\"1\":\"change object\",\n",
    "\"2\":\"add object\",\n",
    "\"3\":\"delete object\", \n",
    "\"4\":\"change content\",\n",
    "\"5\":\"change pose\",\n",
    "\"6\":\"change color\",\n",
    "\"7\":\"change material\",\n",
    "\"8\":\"change background\",\n",
    "\"9\":\"change style\"}\n",
    "\n",
    "def remove_brakets(txt):\n",
    "     return txt.replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "\n",
    "cnt = defaultdict(int)\n",
    "for d in rb:\n",
    "     try:\n",
    "          if d[\"editing_type_id\"] in [] or cnt[d[\"editing_type_id\"]] >= n_examples_per_edit:\n",
    "               continue\n",
    "          if d[\"editing_type_id\"] not in task_ids:\n",
    "               continue\n",
    "          if d[\"original_prompt\"].replace(\"]\", \"\").replace(\"[\", \"\") == \\\n",
    "               d[\"editing_prompt\"].replace(\"]\", \"\").replace(\"[\", \"\"):\n",
    "               continue\n",
    "          key = d[\"id\"]\n",
    "          print(key)\n",
    "          path = os.path.join(prefix, f\"mode{mode}_onlyadd{only_add}_select{aggregate_timesteps}_spatial{keep_spatial_info}_subtract{subtract_target_add_source}_down{use_down}_up{use_up}_up0{use_up0}_mid{use_mid}_T{n_steps}_ktrans{k_transfer}_str{m1}/{d['editing_type_id']}\")\n",
    "          original_prompt = remove_brakets(d[\"original_prompt\"])\n",
    "          editing_prompt = remove_brakets(d[\"editing_prompt\"])\n",
    "          os.makedirs(path, exist_ok=True)\n",
    "          if d[\"editing_type_id\"] in ['0']:\n",
    "               continue\n",
    "          elif d[\"editing_type_id\"] in ['2']: # add object\n",
    "               run_feature_transport(editing_prompt, original_prompt, d[\"editing_gsam_prompt\"], \"#everything\", \n",
    "                    pipe, grounding_model, sam2_predictor, saes,\n",
    "                    use_source_mask_in_both = True, \n",
    "                    subtract_target_add_source = True,\n",
    "                    maintain_spatial_info=keep_spatial_info,\n",
    "                    blocks_to_intervene=blocks_to_intervene, combine_blocks=True,\n",
    "                    n_steps=n_steps, m1=m1, k_transfer=k_transfer, stat=stat, mode=mode, \n",
    "                    aggregate_timesteps=aggregate_timesteps, only_add=only_add,\n",
    "                    result_name=f\"{path}/{key}\")\n",
    "          elif d[\"editing_type_id\"] in ['3']: # delete object\n",
    "               run_feature_transport(editing_prompt, original_prompt, \"#everything\", d[\"original_gsam_prompt\"], \n",
    "                    pipe, grounding_model, sam2_predictor, saes,\n",
    "                    blocks_to_intervene=blocks_to_intervene, combine_blocks=True, \n",
    "                    use_target_mask_in_both=True,\n",
    "                    subtract_target_add_source=True,\n",
    "                    maintain_spatial_info=keep_spatial_info,\n",
    "                    n_steps=n_steps, m1=m1, k_transfer=k_transfer, stat=stat, mode=mode, \n",
    "                    aggregate_timesteps=aggregate_timesteps,\n",
    "                    result_name=f\"{path}/{key}\")\n",
    "          elif d[\"editing_type_id\"] in ['4', '5'] + ['1'] + ['6', '7', '8', '9']: # change\n",
    "               run_feature_transport(editing_prompt, original_prompt, d[\"editing_gsam_prompt\"], d[\"original_gsam_prompt\"], \n",
    "                    pipe, grounding_model, sam2_predictor, saes,\n",
    "                    blocks_to_intervene=blocks_to_intervene, combine_blocks=True, subtract_target_add_source=subtract_target_add_source,\n",
    "                    maintain_spatial_info=keep_spatial_info, only_add=only_add,\n",
    "                    n_steps=n_steps, m1=m1, k_transfer=k_transfer, stat=stat, mode=mode, \n",
    "                    aggregate_timesteps=aggregate_timesteps,\n",
    "                    result_name=f\"{path}/{key}\")\n",
    "          else: \n",
    "               raise ValueError(\"Unsupported editing type.\")\n",
    "          cnt[d[\"editing_type_id\"]] += 1\n",
    "     except Exception as e:\n",
    "          print(e)\n",
    "          continue\n",
    "          "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "riebench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
